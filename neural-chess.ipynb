{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e479780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import *\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3596e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7876a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3061f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading batch number 0\n",
      "Loading batch number 1\n",
      "Loading batch number 2\n",
      "Loading batch number 3\n",
      "Loading batch number 4\n",
      "Loading batch number 5\n",
      "Loading batch number 6\n",
      "Loading batch number 7\n",
      "Loading batch number 8\n",
      "Loading batch number 9\n",
      "Loading batch number 10\n",
      "Loading batch number 11\n",
      "Loading batch number 12\n",
      "Loading batch number 13\n",
      "Loading batch number 14\n",
      "Loading batch number 15\n",
      "Loading batch number 16\n",
      "Loading batch number 17\n",
      "Loading batch number 18\n",
      "Loading batch number 19\n",
      "Loading batch number 20\n",
      "Loading batch number 21\n",
      "Loading batch number 22\n",
      "Loading batch number 23\n",
      "Loading batch number 24\n",
      "Loading batch number 25\n",
      "Loading batch number 26\n",
      "Loading batch number 27\n",
      "Loading batch number 28\n",
      "Loading batch number 29\n"
     ]
    }
   ],
   "source": [
    "TRAIN_AUTOENCODER = 0 \n",
    "TRAIN_NET = 1\n",
    "\n",
    "TOTAL_AE = 250000\n",
    "TOTAL_MLP = 750000\n",
    "\n",
    "BS_AE = 20\n",
    "BS_MLP = 50\n",
    "EPOCHS_AE = 50 \n",
    "EPOCHS_MLP = 201 \n",
    "RATE_AE = 0.005\n",
    "DECAY_AE = 0.98\n",
    "RATE_MLP = 0.005\n",
    "DECAY_MLP = 0.98\n",
    "\n",
    "BIAS = 0.15\n",
    "\n",
    "N_INPUT = 769 \n",
    "ENCODING_1 = 600 \n",
    "ENCODING_2 = 400 \n",
    "ENCODING_3 = 200\n",
    "ENCODING_4 = 100\n",
    "\n",
    "HIDDEN_1 = 200\n",
    "HIDDEN_2 = 400 \n",
    "HIDDEN_3 = 200\n",
    "HIDDEN_4 = 100 \n",
    "N_OUT = 2\n",
    "\n",
    "VOLUME_SIZE = 25000\n",
    "\n",
    "export_path = 'net/exports'\n",
    "\n",
    "#Get the data from the game files\n",
    "validation_test, validation_test_l = getTest(N_INPUT, 40, 44)\n",
    "whiteWins, blackWins = getTrain(N_INPUT, TOTAL_MLP, VOLUME_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8250610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (769,)\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:08:06.629892: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-12 12:08:06.630699: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Creating the siamese autoencoders. SHAPE IS OFF, only position and player to move, not other data\n",
    "input_shape = blackWins[0].shape\n",
    "print(\"Input Shape:\", input_shape)\n",
    "\n",
    "# Layer 1\n",
    "Pos2Vec = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(600, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(769, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be851e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Learning Rate\n",
      "Compiling\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining Learning Rate\")\n",
    "sample_size = 10000\n",
    "# Defining a decaying learning rate\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.005,\n",
    "    decay_steps= sample_size / 200,\n",
    "    decay_rate=0.98,\n",
    "    name=None)\n",
    "    \n",
    "# Compiling model\n",
    "print(\"Compiling\")\n",
    "Pos2Vec.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=lr_schedule),\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d103ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random sample\n",
      "Training\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:08:07.449748: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-12 12:08:07.592425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/625 [============================>.] - ETA: 0s - loss: 0.2497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:08:11.196929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 4s 4ms/step - loss: 0.2497 - val_loss: 0.2491\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2487 - val_loss: 0.2482\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2479 - val_loss: 0.2475\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2473 - val_loss: 0.2470\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2468 - val_loss: 0.2465\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2464 - val_loss: 0.2462\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2461 - val_loss: 0.2459\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2459 - val_loss: 0.2457\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2457 - val_loss: 0.2456\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2455 - val_loss: 0.2455\n"
     ]
    }
   ],
   "source": [
    "# whiteWins, blackWins\n",
    "print(\"Generating random train\")\n",
    "sample_size = 10000#1000000\n",
    "test_size= 1000#1000\n",
    "white_sample = whiteWins[np.random.randint(whiteWins.shape[0], size=sample_size), :]\n",
    "black_sample = blackWins[np.random.randint(blackWins.shape[0], size=sample_size), :]\n",
    "\n",
    "white_test = whiteWins[np.random.randint(whiteWins.shape[0], size=test_size), :]\n",
    "black_test = blackWins[np.random.randint(blackWins.shape[0], size=test_size), :]\n",
    "\n",
    "autoencoder_train = np.concatenate([white_sample, black_sample])\n",
    "autoencoder_test = np.concatenate([white_test, black_test])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=500,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "print(\"Training\")\n",
    "history = Pos2Vec.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa81313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_1 = Pos2Vec.layers[0] # 769 - 600nodes\n",
    "layer_2 = Pos2Vec.layers[1] # 600 - 769nodes\n",
    "\n",
    "layer_1.trainable = False\n",
    "layer_2.trainable = False\n",
    "\n",
    "Pos2Vec_2 = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layers.Dense(400, activation='relu'),\n",
    "    layers.Dense(600, activation='relu'),\n",
    "    layer_2,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978255ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.005,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.98)\n",
    "\n",
    "decay_optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e52ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "Pos2Vec_2.compile(\n",
    "    optimizer=decay_optimizer,\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7767801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/10\n",
      " 19/625 [..............................] - ETA: 3s - loss: 0.2478 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:08:34.646220: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/625 [============================>.] - ETA: 0s - loss: 0.2477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:08:37.333993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2477 - val_loss: 0.2475\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2474 - val_loss: 0.2472\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2470 - val_loss: 0.2469\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2467 - val_loss: 0.2465\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2464 - val_loss: 0.2462\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2460 - val_loss: 0.2458\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2456 - val_loss: 0.2454\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2452 - val_loss: 0.2450\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2448 - val_loss: 0.2446\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2444 - val_loss: 0.2442\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "history = Pos2Vec_2.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d75aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_3 = Pos2Vec_2.layers[1] # 600 - 400nodes\n",
    "layer_4 = Pos2Vec_2.layers[2] # 400 - 600nodes\n",
    "\n",
    "layer_3.trainable = False\n",
    "layer_4.trainable = False\n",
    "\n",
    "Pos2Vec_3 = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layer_3,\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layers.Dense(400, activation='relu'),\n",
    "    layer_4,\n",
    "    layer_2,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e4ccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "Pos2Vec_3.compile(\n",
    "    optimizer=decay_optimizer,\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c02137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/10\n",
      " 14/625 [..............................] - ETA: 2s - loss: 0.2475  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:09:03.357202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/625 [============================>.] - ETA: 0s - loss: 0.2474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:09:06.128678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2474 - val_loss: 0.2474\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2473 - val_loss: 0.2473\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2472 - val_loss: 0.2471\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2471 - val_loss: 0.2470\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2470 - val_loss: 0.2469\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2469 - val_loss: 0.2468\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2467 - val_loss: 0.2467\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2466 - val_loss: 0.2465\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2465 - val_loss: 0.2464\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2463 - val_loss: 0.2462\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "history = Pos2Vec_3.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb37880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_5 = Pos2Vec_3.layers[2] # 400 - 200nodes\n",
    "layer_6 = Pos2Vec_3.layers[3] # 200 - 400nodes\n",
    "\n",
    "layer_5.trainable = False\n",
    "layer_6.trainable = False\n",
    "\n",
    "Pos2Vec_4 = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layer_3,\n",
    "    layer_5,\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layer_6,\n",
    "    layer_4,\n",
    "    layer_2,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a74eb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compiling model\n",
    "Pos2Vec_4.compile(\n",
    "    optimizer=decay_optimizer,\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a0ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/10\n",
      "  1/625 [..............................] - ETA: 3:23 - loss: 0.2474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:09:32.472992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/625 [============================>.] - ETA: 0s - loss: 0.2474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 12:09:35.610989: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 4s 5ms/step - loss: 0.2474 - val_loss: 0.2474\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2474 - val_loss: 0.2473\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2473 - val_loss: 0.2473\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2473 - val_loss: 0.2473\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2472 - val_loss: 0.2472\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2472 - val_loss: 0.2472\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2472 - val_loss: 0.2471\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2471 - val_loss: 0.2471\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2471 - val_loss: 0.2471\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2470 - val_loss: 0.2470\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "history = Pos2Vec_4.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4d86927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_7 = Pos2Vec_4.layers[3] # 400 - 200nodes\n",
    "layer_8 = Pos2Vec_4.layers[4] # 200 - 400nodes\n",
    "\n",
    "layer_7.trainable = False\n",
    "layer_8.trainable = False\n",
    "\n",
    "Pos2Vec_A = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layer_3,\n",
    "    layer_5,\n",
    "    layer_7,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import concatenate\n",
    "\n",
    "pydot = pydotplus\n",
    "\n",
    "# Duplicating siamese Pos2Vec with tied weights\n",
    "la0, la1, la2, la3 = Pos2Vec_A.layers\n",
    "Pos2Vec_B_in = keras.layers.Input(shape=(769,))\n",
    "lc0 = la0(Pos2Vec_B_in)\n",
    "lc1 = la1(lc0)\n",
    "lc2 = la2(lc1)\n",
    "lc2 = la3(lc2)\n",
    "\n",
    "Pos2Vec_B = keras.Model(inputs=Pos2Vec_B_in, outputs=lc2)\n",
    "\n",
    "# Creating DeepChess layers to compare pos2vec\n",
    "twin_p2v_in = concatenate([Pos2Vec_A.output, Pos2Vec_B.output])\n",
    "l0 = layers.Dense(400, activation=\"relu\")(twin_p2v_in)\n",
    "l1 = layers.Dense(200, activation=\"relu\")(l0)\n",
    "l2 = layers.Dense(100, activation=\"relu\")(l1)\n",
    "deepchess_out = layers.Dense(2, activation=\"relu\")(l2)\n",
    "\n",
    "DeepChess = keras.Model(\n",
    "    inputs=[Pos2Vec_A.input, Pos2Vec_B.input], \n",
    "    outputs=[deepchess_out])\n",
    "\n",
    "plot_model(DeepChess,\n",
    "            show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7a8cfbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random sample\n"
     ]
    }
   ],
   "source": [
    "# whiteWins, blackWins\n",
    "print(\"Generating random sample\")\n",
    "train_size = 10000#1000000\n",
    "test_size= 1000#100000\n",
    "\n",
    "## Generating training data\n",
    "# sampling white wins and losses (black wins)\n",
    "white_w_train = whiteWins[np.random.randint(whiteWins.shape[0], size=train_size), :]\n",
    "white_l_train = blackWins[np.random.randint(blackWins.shape[0], size=train_size), :]\n",
    "\n",
    "# Creating (W, L) or (L, W) pairs\n",
    "DeepChess_in_A = np.concatenate((white_w_train[:train_size // 2], white_l_train[:train_size // 2]))\n",
    "DeepChess_in_B = np.concatenate((white_l_train[train_size // 2:], white_w_train[train_size // 2:]))\n",
    "\n",
    "# Creating (1, 0) or (0, 1) pairs corresponding to input\n",
    "DeepChess_out = np.array([(1,0)] * (train_size // 2) + \n",
    "                            [(0,1)] * (train_size // 2))\n",
    "\n",
    "\n",
    "## Generating testing data\n",
    "# test white wins and losses (black wins)\n",
    "white_w_test= whiteWins[np.random.randint(whiteWins.shape[0], size=test_size), :]\n",
    "white_l_test= blackWins[np.random.randint(blackWins.shape[0], size=test_size), :]\n",
    "\n",
    "# Creating (W, L) or (L, W) pairs\n",
    "DeepChess_test_in_A = np.concatenate((white_w_test[:test_size // 2], white_l_test[:test_size // 2]))\n",
    "DeepChess_test_in_B = np.concatenate((white_l_test[test_size // 2:], white_w_test[test_size // 2:]))\n",
    "\n",
    "# Creating (1, 0) or (0, 1) pairs corresponding to input\n",
    "DeepChess_test_out = np.array([(1,0)] * (test_size // 2) + \n",
    "                            [(0,1)] * (test_size // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7171aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "DeepChess.compile(\n",
    "    optimizer=decay_optimizer,\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "24e839ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/100\n",
      "  1/282 [..............................] - ETA: 1:13 - loss: 0.4553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 19:23:43.937288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - ETA: 0s - loss: 0.2693"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 19:23:46.065445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 2s 8ms/step - loss: 0.2693 - val_loss: 0.3143\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2481 - val_loss: 0.3097\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2478 - val_loss: 0.3128\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2475 - val_loss: 0.3073\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2472 - val_loss: 0.2929\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2471 - val_loss: 0.3118\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2469 - val_loss: 0.2930\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2467 - val_loss: 0.2982\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2466 - val_loss: 0.3179\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2464 - val_loss: 0.3140\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2464 - val_loss: 0.3098\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2462 - val_loss: 0.3173\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2461 - val_loss: 0.3292\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2461 - val_loss: 0.2959\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2460 - val_loss: 0.3114\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2459 - val_loss: 0.3094\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2458 - val_loss: 0.3122\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2457 - val_loss: 0.3180\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2457 - val_loss: 0.3061\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2456 - val_loss: 0.3214\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2455 - val_loss: 0.3141\n",
      "Epoch 22/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2455 - val_loss: 0.3090\n",
      "Epoch 23/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2454 - val_loss: 0.2910\n",
      "Epoch 24/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2455 - val_loss: 0.3174\n",
      "Epoch 25/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2454 - val_loss: 0.3141\n",
      "Epoch 26/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2453 - val_loss: 0.3113\n",
      "Epoch 27/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2452 - val_loss: 0.3079\n",
      "Epoch 28/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2452 - val_loss: 0.3096\n",
      "Epoch 29/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2451 - val_loss: 0.2916\n",
      "Epoch 30/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2450 - val_loss: 0.3018\n",
      "Epoch 31/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2450 - val_loss: 0.3111\n",
      "Epoch 32/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2450 - val_loss: 0.2885\n",
      "Epoch 33/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2448 - val_loss: 0.3012\n",
      "Epoch 34/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2448 - val_loss: 0.3003\n",
      "Epoch 35/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2448 - val_loss: 0.3027\n",
      "Epoch 36/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2447 - val_loss: 0.3046\n",
      "Epoch 37/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2446 - val_loss: 0.2781\n",
      "Epoch 38/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2447 - val_loss: 0.3055\n",
      "Epoch 39/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2446 - val_loss: 0.3016\n",
      "Epoch 40/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2445 - val_loss: 0.2885\n",
      "Epoch 41/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2445 - val_loss: 0.3064\n",
      "Epoch 42/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2444 - val_loss: 0.2889\n",
      "Epoch 43/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2444 - val_loss: 0.3317\n",
      "Epoch 44/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2443 - val_loss: 0.3142\n",
      "Epoch 45/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2443 - val_loss: 0.2908\n",
      "Epoch 46/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2442 - val_loss: 0.2773\n",
      "Epoch 47/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2442 - val_loss: 0.3195\n",
      "Epoch 48/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2440 - val_loss: 0.2904\n",
      "Epoch 49/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2441 - val_loss: 0.3095\n",
      "Epoch 50/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2441 - val_loss: 0.2976\n",
      "Epoch 51/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2439 - val_loss: 0.3164\n",
      "Epoch 52/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2439 - val_loss: 0.2997\n",
      "Epoch 53/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2439 - val_loss: 0.3070\n",
      "Epoch 54/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2439 - val_loss: 0.3077\n",
      "Epoch 55/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2438 - val_loss: 0.3018\n",
      "Epoch 56/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2438 - val_loss: 0.3049\n",
      "Epoch 57/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2437 - val_loss: 0.3246\n",
      "Epoch 58/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2437 - val_loss: 0.3082\n",
      "Epoch 59/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2436 - val_loss: 0.3041\n",
      "Epoch 60/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2434 - val_loss: 0.2962\n",
      "Epoch 61/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2436 - val_loss: 0.3255\n",
      "Epoch 62/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2435 - val_loss: 0.2961\n",
      "Epoch 63/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2434 - val_loss: 0.3066\n",
      "Epoch 64/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2432 - val_loss: 0.2749\n",
      "Epoch 65/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2433 - val_loss: 0.2798\n",
      "Epoch 66/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2433 - val_loss: 0.3037\n",
      "Epoch 67/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2432 - val_loss: 0.2847\n",
      "Epoch 68/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2432 - val_loss: 0.2951\n",
      "Epoch 69/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2431 - val_loss: 0.3173\n",
      "Epoch 70/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2431 - val_loss: 0.3109\n",
      "Epoch 71/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2430 - val_loss: 0.3020\n",
      "Epoch 72/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2428 - val_loss: 0.3182\n",
      "Epoch 73/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2429 - val_loss: 0.2917\n",
      "Epoch 74/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2429 - val_loss: 0.2993\n",
      "Epoch 75/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2429 - val_loss: 0.2935\n",
      "Epoch 76/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2428 - val_loss: 0.3098\n",
      "Epoch 77/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2427 - val_loss: 0.2926\n",
      "Epoch 78/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2427 - val_loss: 0.3210\n",
      "Epoch 79/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2426 - val_loss: 0.3182\n",
      "Epoch 80/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2425 - val_loss: 0.2877\n",
      "Epoch 81/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2425 - val_loss: 0.3272\n",
      "Epoch 82/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2422 - val_loss: 0.3473\n",
      "Epoch 83/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2424 - val_loss: 0.3110\n",
      "Epoch 84/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2423 - val_loss: 0.3210\n",
      "Epoch 85/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2423 - val_loss: 0.2947\n",
      "Epoch 86/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2422 - val_loss: 0.2965\n",
      "Epoch 87/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2421 - val_loss: 0.3007\n",
      "Epoch 88/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2421 - val_loss: 0.3221\n",
      "Epoch 89/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2421 - val_loss: 0.2989\n",
      "Epoch 90/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2420 - val_loss: 0.2965\n",
      "Epoch 91/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2421 - val_loss: 0.2973\n",
      "Epoch 92/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2419 - val_loss: 0.3279\n",
      "Epoch 93/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2417 - val_loss: 0.2992\n",
      "Epoch 94/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2417 - val_loss: 0.3360\n",
      "Epoch 95/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2417 - val_loss: 0.2788\n",
      "Epoch 96/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2417 - val_loss: 0.3390\n",
      "Epoch 97/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2417 - val_loss: 0.3010\n",
      "Epoch 98/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2416 - val_loss: 0.2900\n",
      "Epoch 99/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2415 - val_loss: 0.2866\n",
      "Epoch 100/100\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2414 - val_loss: 0.3081\n"
     ]
    }
   ],
   "source": [
    "lr_schedule2 = keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.01,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.99)\n",
    "\n",
    "decay_optimizer2 = keras.optimizers.SGD(learning_rate=lr_schedule2)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=500,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "print(\"Training\")\n",
    "history = DeepChess.fit(\n",
    "    x=[DeepChess_in_A, DeepChess_in_B], y=DeepChess_out,\n",
    "    validation_split=0.1,\n",
    "    batch_size=None,\n",
    "    epochs=100, #1000\n",
    "    callbacks=[early_stopping],\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
