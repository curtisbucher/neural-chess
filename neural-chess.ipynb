{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e479780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import *\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3596e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a7876a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d3061f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading batch number 0\n",
      "Loading batch number 1\n",
      "Loading batch number 2\n",
      "Loading batch number 3\n",
      "Loading batch number 4\n",
      "Loading batch number 5\n",
      "Loading batch number 6\n",
      "Loading batch number 7\n",
      "Loading batch number 8\n",
      "Loading batch number 9\n",
      "Loading batch number 10\n",
      "Loading batch number 11\n",
      "Loading batch number 12\n",
      "Loading batch number 13\n",
      "Loading batch number 14\n",
      "Loading batch number 15\n",
      "Loading batch number 16\n",
      "Loading batch number 17\n",
      "Loading batch number 18\n",
      "Loading batch number 19\n",
      "Loading batch number 20\n",
      "Loading batch number 21\n",
      "Loading batch number 22\n",
      "Loading batch number 23\n",
      "Loading batch number 24\n",
      "Loading batch number 25\n",
      "Loading batch number 26\n",
      "Loading batch number 27\n",
      "Loading batch number 28\n",
      "Loading batch number 29\n"
     ]
    }
   ],
   "source": [
    "TRAIN_AUTOENCODER = 0 \n",
    "TRAIN_NET = 1\n",
    "\n",
    "TOTAL_AE = 250000\n",
    "TOTAL_MLP = 750000\n",
    "\n",
    "BS_AE = 20\n",
    "BS_MLP = 50\n",
    "EPOCHS_AE = 50 \n",
    "EPOCHS_MLP = 201 \n",
    "RATE_AE = 0.005\n",
    "DECAY_AE = 0.98\n",
    "RATE_MLP = 0.005\n",
    "DECAY_MLP = 0.98\n",
    "\n",
    "BIAS = 0.15\n",
    "\n",
    "N_INPUT = 769 \n",
    "ENCODING_1 = 600 \n",
    "ENCODING_2 = 400 \n",
    "ENCODING_3 = 200\n",
    "ENCODING_4 = 100\n",
    "\n",
    "HIDDEN_1 = 200\n",
    "HIDDEN_2 = 400 \n",
    "HIDDEN_3 = 200\n",
    "HIDDEN_4 = 100 \n",
    "N_OUT = 2\n",
    "\n",
    "VOLUME_SIZE = 25000\n",
    "\n",
    "export_path = 'net/exports'\n",
    "\n",
    "#Get the data from the game files\n",
    "validation_test, validation_test_l = getTest(N_INPUT, 40, 44)\n",
    "whiteWins, blackWins = getTrain(N_INPUT, TOTAL_MLP, VOLUME_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8250610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (769,)\n"
     ]
    }
   ],
   "source": [
    "# Creating the siamese autoencoders. SHAPE IS OFF, only position and player to move, not other data\n",
    "input_shape = blackWins[0].shape\n",
    "print(\"Input Shape:\", input_shape)\n",
    "\n",
    "# Layer 1\n",
    "Pos2Vec = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(600, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(769, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be851e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Learning Rate\n",
      "Compiling\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining Learning Rate\")\n",
    "sample_size = 10000\n",
    "# Defining a decaying learning rate\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.005,\n",
    "    decay_steps= sample_size / 200,\n",
    "    decay_rate=0.98,\n",
    "    name=None)\n",
    "    \n",
    "# Compiling model\n",
    "print(\"Compiling\")\n",
    "Pos2Vec.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d103ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random sample\n",
      "Training\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.2507 - val_loss: 0.2500\n",
      "Epoch 2/10\n",
      "596/625 [===========================>..] - ETA: 0s - loss: 0.2496"
     ]
    }
   ],
   "source": [
    "# whiteWins, blackWins\n",
    "print(\"Generating random sample\")\n",
    "sample_size = 10000#1000000\n",
    "test_size= 1000#1000\n",
    "white_sample = whiteWins[np.random.randint(whiteWins.shape[0], size=sample_size), :]\n",
    "black_sample = blackWins[np.random.randint(blackWins.shape[0], size=sample_size), :]\n",
    "\n",
    "white_test = whiteWins[np.random.randint(whiteWins.shape[0], size=test_size), :]\n",
    "black_test = blackWins[np.random.randint(blackWins.shape[0], size=test_size), :]\n",
    "\n",
    "autoencoder_train = np.concatenate([white_sample, black_sample])\n",
    "autoencoder_test = np.concatenate([white_test, black_test])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=500,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "print(\"Training\")\n",
    "history = Pos2Vec.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa81313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_1 = Pos2Vec.layers[0] # 769 - 600nodes\n",
    "layer_2 = Pos2Vec.layers[1] # 600 - 769nodes\n",
    "\n",
    "layer_1.trainable = False\n",
    "layer_2.trainable = False\n",
    "\n",
    "Pos2Vec_2 = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layers.Dense(400, activation='relu'),\n",
    "    layers.Dense(600, activation='relu'),\n",
    "    layer_2,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e52ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "Pos2Vec_2.compile(\n",
    "    optimizer=decay_optimizer,\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "history = Pos2Vec_4.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_3 = Pos2Vec_2.layers[1] # 600 - 400nodes\n",
    "layer_4 = Pos2Vec_2.layers[2] # 400 - 600nodes\n",
    "\n",
    "layer_3.trainable = False\n",
    "layer_4.trainable = False\n",
    "\n",
    "Pos2Vec_3 = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layer_3,\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layers.Dense(400, activation='relu'),\n",
    "    layer_4,\n",
    "    layer_2,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "Pos2Vec_3.compile(\n",
    "    optimizer=decay_optimizer,\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "history = Pos2Vec_3.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb37880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_5 = Pos2Vec_3.layers[2] # 400 - 200nodes\n",
    "layer_6 = Pos2Vec_3.layers[3] # 200 - 400nodes\n",
    "\n",
    "layer_5.trainable = False\n",
    "layer_6.trainable = False\n",
    "\n",
    "Pos2Vec_4 = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layer_3,\n",
    "    layer_5,\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layer_6,\n",
    "    layer_4,\n",
    "    layer_2,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74eb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compiling model\n",
    "Pos2Vec_4.compile(\n",
    "    optimizer=decay_optimizer,\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "history = Pos2Vec_4.fit(\n",
    "    autoencoder_train, autoencoder_train,\n",
    "    validation_data=(autoencoder_test, autoencoder_test),\n",
    "    batch_size=None,\n",
    "    epochs=10, #200\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d86927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the 400 node layer\n",
    "layer_7 = Pos2Vec_4.layers[3] # 400 - 200nodes\n",
    "layer_8 = Pos2Vec_4.layers[4] # 200 - 400nodes\n",
    "\n",
    "layer_7.trainable = False\n",
    "layer_8.trainable = False\n",
    "\n",
    "Pos2Vec_Final = keras.Sequential([\n",
    "    # layers.Dense(769, activation='relu', input_shape=input_shape),\n",
    "    layer_1,\n",
    "    layer_3,\n",
    "    layer_5,\n",
    "    layer_7,\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
